# SimpleRAG - Application de Retrieval Augmented Generation

Cette application Streamlit implÃ©mente un systÃ¨me de Retrieval Augmented Generation (RAG) permettant d'interroger des documents scientifiques au format XML-TEI. L'application utilise au choix plusieurs LLMs via l'API Hugging Face ou GPT-3.5 via l'API OpenAI pour gÃ©nÃ©rer des rÃ©ponses prÃ©cises Ã  partir de votre corpus de documents.

## ğŸŒŸ FonctionnalitÃ©s

- **Interface conversationnelle** pour poser des questions sur vos documents
- **Support de multiples LLMs** : choix entre Llama 3, GPT-3.5, Mistral Small 24B et Phi-4-mini
- **Traitement de corpus personnalisÃ©** via l'upload de fichiers XML-TEI
- **Affichage des sources** pour chaque rÃ©ponse avec mÃ©tadonnÃ©es dÃ©taillÃ©es
- **Personnalisation avancÃ©e** du prompt systÃ¨me pour ajuster les rÃ©ponses
- **Visualisation des extraits** de texte pertinents pour chaque rÃ©ponse

## ğŸ“‹ PrÃ©requis pour le dÃ©ploiement

- Compte Streamlit (mÃªme gratuit)
- Compte Hugging Face (pour l'API key)
- Compte OpenAI (optionnel, pour utiliser GPT-3.5 avec l'API key)

## ğŸš€ Lancement de l'application

L'application actuelle est exÃ©cutÃ©e directement via le service Streamlit, qui prend en entrÃ©e le rÃ©pertoire GitHub et construit l'application sur leur infrastructure cloud, la rendant immÃ©diatement utilisable. Pour cela, il est nÃ©cessaire de disposer d'un compte Streamlit et de crÃ©er un projet. Les instructions sur leur site sont claires et faciles Ã  suivre.

## ğŸ“Š Structure du projet

```
simple-rag/
â”œâ”€â”€ app.py              # Application Streamlit principale
â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”œâ”€â”€ README.md           # Documentation (ce fichier)
â”œâ”€â”€ .gitignore          # Fichiers ignorÃ©s par Git
â””â”€â”€ data/               # RÃ©pertoire pour les documents Ã  traiter par dÃ©faut
```

## ğŸ“ Guide d'utilisation

### Configurer l'application
1. Dans la barre latÃ©rale, entrez votre clÃ© API Hugging Face (obligatoire)
2. Si vous souhaitez utiliser GPT-3.5, entrez Ã©galement votre clÃ© API OpenAI
3. Choisissez le modÃ¨le LLM Ã  utiliser parmi les 4 options disponibles

### Ajouter des documents
1. TÃ©lÃ©chargez vos fichiers XML-TEI via le sÃ©lecteur de fichiers dans la barre latÃ©rale
2. Cochez "Utiliser uniquement les fichiers tÃ©lÃ©chargÃ©s" si vous ne voulez pas utiliser le corpus par dÃ©faut
3. Cliquez sur "Traiter les documents" pour indexer votre corpus (cela peut prendre un peu du temps)

### Interroger votre corpus
1. Saisissez votre question dans le champ de texte en bas de l'Ã©cran
2. Consultez la rÃ©ponse gÃ©nÃ©rÃ©e et les sources utilisÃ©es
3. Cliquez sur les sources pour voir les extraits exacts utilisÃ©s pour la rÃ©ponse

### Personnaliser les rÃ©ponses
Pour ajuster le style ou le comportement des rÃ©ponses, utilisez l'option "Options avancÃ©es" pour modifier le prompt systÃ¨me.

## ğŸ§  SpÃ©cifications techniques

### LLMs utilisÃ©s
- **Llama 3** : Meta-Llama-3-8B-Instruct via l'API Hugging Face
- **GPT-3.5** : gpt-3.5-turbo via l'API OpenAI
- **Mistral Small** : Mistral-Small-24B-Instruct-2501 via l'API Hugging Face  
- **Phi-4-mini** : Phi-4-mini-instruct via l'API Hugging Face
- **TempÃ©rature** : 0.4 
- **Tokens maximum** : 512
- **Top_p** : 0.95 (permet une diversitÃ© contrÃ´lÃ©e dans les rÃ©ponses)

### Traitement des documents
- **Technique de chunking** : [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/) de Langchain
- **Taille des chunks** : 1000 caractÃ¨res
- **Chevauchement** : 100 caractÃ¨res (assure une continuitÃ© entre les chunks)
- **Extraction des mÃ©tadonnÃ©es** : titre, date, personnes mentionnÃ©es
- **Organisation** : mÃ©tadonnÃ©es en en-tÃªte pour contextualiser les chunks

### Embeddings et recherche
- **ModÃ¨le d'embedding** : [sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) (optimisÃ© pour le franÃ§ais)
- **Base de donnÃ©es vectorielle** : FAISS (rapide et efficace pour la recherche de similaritÃ©)
- **Configuration du retriever** : k=3 (rÃ©cupÃ¨re les 3 documents les plus pertinents)

## ğŸ”„ Format des fichiers XML-TEI supportÃ©s

L'application est conÃ§ue pour traiter des documents XML-TEI avec les balises suivantes :
- `<tei:titleStmt>/<tei:title>` pour le titre du document
- `<tei:sourceDesc>/<tei:p>/<tei:date>` pour la date
- `<tei:p>` pour les paragraphes de contenu
- `<tei:persName>` pour les noms de personnes mentionnÃ©es

## ğŸ“„ Licence

Ce projet est sous une licence open source MIT. 

## ğŸ¤ Contributions

Le projet est prÃ©parÃ© par [Mikhail Biriuchinskii](https://www.linkedin.com/in/mikhail-biriuchinskii/), ingÃ©nieur en Traitement Automatique des Langues, Ã©quipe ObTIC, Sorbonne UniversitÃ©.

Pour dÃ©couvrir d'autres projets de l'Ã©quipe ObTIC ainsi que les formations proposÃ©es, consultez le site : https://obtic.sorbonne-universite.fr/
